{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnaydos11/Fruit_Detection_Pruning_Quantization/blob/main/Fruit_Detection_Pruning_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX-7JshQlSbW",
        "outputId": "7b0743ac-2faa-4beb-aa0b-ae10c6d6c49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ],
      "source": [
        "pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-model-optimization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjwNK-WMy4hx",
        "outputId": "22ca0366-b91b-428b-9d77-b05c6693db21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BknJ4wspX5Vi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "import psutil  # For memory usage\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from memory_profiler import profile\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOQZhMGJYCM7"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/Fruit Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wBdd2dgYyUJ"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2BnnSc4Y13A",
        "outputId": "9dd29719-e015-4ddc-ea2b-52aa3f6c93cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1709"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN6GaziCY39S"
      },
      "outputs": [],
      "source": [
        "#sınıflardaki fotoğraflar etiketleme işlemi\n",
        "fruit_images_dict = {\n",
        "    'apple' : list(data_dir.glob('apple/*')),\n",
        "    'orange' : list(data_dir.glob('orange/*')),\n",
        "    'mandarin' : list(data_dir.glob('mandarin/*')),\n",
        "    'banana' : list(data_dir.glob('banana/*'))\n",
        "}\n",
        "fruit_labels_dict = {\n",
        "    'apple': 0,\n",
        "    'orange' : 1,\n",
        "    'mandarin' :2,\n",
        "    'banana' :3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNnKM8z6Y6n-"
      },
      "outputs": [],
      "source": [
        "#boyutlandırma işlemi\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for fruit_name, images in fruit_images_dict.items():\n",
        "    for image in images:\n",
        "        img = cv2.imread(str(image))\n",
        "        resized_img = cv2.resize(img, (180, 180))\n",
        "        X.append(resized_img)\n",
        "        y.append(fruit_labels_dict[fruit_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnOL1eB5Y7ie"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HykvvMBY8lo"
      },
      "outputs": [],
      "source": [
        "# Veri setini eğitim ve test kümelerine bölelim\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7Ba3iCQffhp"
      },
      "outputs": [],
      "source": [
        "#normalizasyon işlemi\n",
        "X_train_scaled = X_train / 255\n",
        "X_test_scaled = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iEYw0chbVQE",
        "outputId": "4a81b756-b5e2-4a20-a4c1-bcc54c3b6a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "89/89 [==============================] - 158s 2s/step - loss: 0.7688 - accuracy: 0.7734\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 155s 2s/step - loss: 0.4918 - accuracy: 0.8513\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 144s 2s/step - loss: 0.3467 - accuracy: 0.8902\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 146s 2s/step - loss: 0.3370 - accuracy: 0.8938\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 156s 2s/step - loss: 0.2959 - accuracy: 0.9001\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 148s 2s/step - loss: 0.2375 - accuracy: 0.9200\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 147s 2s/step - loss: 0.1918 - accuracy: 0.9370\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 147s 2s/step - loss: 0.1987 - accuracy: 0.9412\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 157s 2s/step - loss: 0.1683 - accuracy: 0.9448\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 148s 2s/step - loss: 0.1250 - accuracy: 0.9547\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 180, 180, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 180, 180, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 90, 90, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 90, 90, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 90, 90, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 45, 45, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 45, 45, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 45, 45, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 22, 22, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 61952)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               15859968  \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15989189 (60.99 MB)\n",
            "Trainable params: 15987973 (60.99 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n",
            "Training Time: 1531.0692460536957 seconds\n",
            "Memory Usage: 6.680881500244141 MB\n"
          ]
        }
      ],
      "source": [
        "import tracemalloc\n",
        "# memory usage kontrolü\n",
        "tracemalloc.start()\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# eğitim zamanını ve hafıza kullanımını hesaplama\n",
        "start_time = time.time()\n",
        "start_memory = tracemalloc.get_traced_memory()\n",
        "\n",
        "history =  model.fit(X_train_scaled, y_train, epochs=10, batch_size=16)\n",
        "# Modelin summary'sini yazdırma\n",
        "model.summary()\n",
        "\n",
        "end_time = time.time()\n",
        "end_memory = tracemalloc.get_traced_memory()\n",
        "training_time = end_time - start_time\n",
        "memory_usage = end_memory[0] - start_memory[0]\n",
        "\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "print(f\"Memory Usage: {memory_usage / (1024 ** 2)} MB\")  # Convert to megabytes\n",
        "tracemalloc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwpl5hjbbaHo",
        "outputId": "af33d4de-3721-4b92-880c-5b7898013284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 11s 891ms/step - loss: 0.2193 - accuracy: 0.9463\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21932779252529144, 0.9463276863098145]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.evaluate(X_test_scaled,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Orijinal modelin kaydedilmesi\n",
        "model.save('original_model.h5')\n"
      ],
      "metadata": {
        "id": "rIRfx0tnlEDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b028211a-3615-47e5-8e7a-933411787f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute end step to finish pruning after 5 epochs.\n",
        "batch_size = 16\n",
        "epochs = 2  # Eğitimde kullanılacak toplam dönem sayısı\n",
        "validation_split = 0.1  # Eğitim setinin %10'u doğrulama seti olarak ayrılacak.\n",
        "\n",
        "# Eğitim setindeki görüntü sayısını hesaplayarak pruning işleminin ne zaman biteceğini belirleme\n",
        "num_images = X_train_scaled.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Pruning için parametrelerin ayarlanması\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                             final_sparsity=0.90,\n",
        "                                                             begin_step=0,\n",
        "                                                             end_step=end_step)\n",
        "}\n",
        "\n",
        "# Pruning işleminin uygulanması\n",
        "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Pruned modelin derlenmesi\n",
        "pruned_model.compile(optimizer='adam',\n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Eğitim öncesi hafıza ve zaman ölçümü\n",
        "tracemalloc.start()\n",
        "start_time = time.time()\n",
        "start_memory = tracemalloc.get_traced_memory()\n",
        "\n",
        "# Pruned modelin eğitilmesi\n",
        "callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir='/tmp/logs')\n",
        "]\n",
        "\n",
        "history = pruned_model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks,\n",
        "                           validation_split=validation_split)  # Eğitim ve doğrulama setlerini kullanarak modeli eğitme\n",
        "\n",
        "# Pruned modelin özetini görüntüleme\n",
        "pruned_model.summary()\n",
        "\n",
        "# Eğitim sonrası hafıza ve zaman ölçümü\n",
        "end_time = time.time()\n",
        "end_memory = tracemalloc.get_traced_memory()\n",
        "training_time = end_time - start_time\n",
        "memory_usage = end_memory[0] - start_memory[0]\n",
        "\n",
        "print(f\"Pruned Training Time: {training_time} seconds\")\n",
        "print(f\"Pruned Memory Usage: {memory_usage / (1024 ** 2)} MB\")  # Megabayt cinsinden bellek kullanımını görüntüleme\n",
        "tracemalloc.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4H-XvHdhw21",
        "outputId": "1f190749-1569-481c-c931-cfb7e58bdcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "80/80 [==============================] - 165s 2s/step - loss: 0.1597 - accuracy: 0.9543 - val_loss: 0.0749 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "80/80 [==============================] - 143s 2s/step - loss: 0.4656 - accuracy: 0.8669 - val_loss: 0.8319 - val_accuracy: 0.7746\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 180, 180, 32)      1762      \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_  (None, 180, 180, 32)      129       \n",
            " normalization (PruneLowMag                                      \n",
            " nitude)                                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 90, 90, 32)        1         \n",
            " oling2d (PruneLowMagnitude                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 90, 90, 64)        36930     \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_  (None, 90, 90, 64)        257       \n",
            " normalization_1 (PruneLowM                                      \n",
            " agnitude)                                                       \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 45, 45, 64)        1         \n",
            " oling2d_1 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 45, 45, 128)       147586    \n",
            " _2 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_  (None, 45, 45, 128)       513       \n",
            " normalization_2 (PruneLowM                                      \n",
            " agnitude)                                                       \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 22, 22, 128)       1         \n",
            " oling2d_2 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 61952)             1         \n",
            " n (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 256)               31719682  \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_  (None, 256)               1025      \n",
            " normalization_3 (PruneLowM                                      \n",
            " agnitude)                                                       \n",
            "                                                                 \n",
            " prune_low_magnitude_dropou  (None, 256)               1         \n",
            " t (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 128)               65666     \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_  (None, 128)               513       \n",
            " normalization_4 (PruneLowM                                      \n",
            " agnitude)                                                       \n",
            "                                                                 \n",
            " prune_low_magnitude_dropou  (None, 128)               1         \n",
            " t_1 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 5)                 1287      \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31975356 (121.98 MB)\n",
            "Trainable params: 15987973 (60.99 MB)\n",
            "Non-trainable params: 15987383 (60.99 MB)\n",
            "_________________________________________________________________\n",
            "Pruned Training Time: 340.1332218647003 seconds\n",
            "Pruned Memory Usage: 11.208130836486816 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.evaluate(X_test_scaled,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGYltjKsuMBY",
        "outputId": "a05ac65d-4ea0-4d7b-a796-ced6df7ac0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 10s 706ms/step - loss: 0.5864 - accuracy: 0.8898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.586379885673523, 0.8898305296897888]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning wrapper'ını kaldırma\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "# Modeli kaydetme\n",
        "model_for_export.save('pruned_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXWBUNcDh2S9",
        "outputId": "96ea34ac-a8c5-4ad2-9a9d-b2c73b1d5a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Lite Converter kullanarak kuantizasyon\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Kuantize edilmiş modeli dönüştürme\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# TFLite modelini dosyaya kaydetme\n",
        "with open('quantized_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "zglmDWxilUSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Lite modelini yükleyin\n",
        "interpreter = tf.lite.Interpreter(model_path='quantized_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Modelin giriş ve çıkış detaylarını alın\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "def evaluate_tflite_model(interpreter, test_images, test_labels):\n",
        "    input_index = input_details[0]['index']\n",
        "    output_index = output_details[0]['index']\n",
        "\n",
        "    prediction_labels = []\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "        input_data = np.expand_dims(test_images[i], axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_index)\n",
        "        predicted_label = np.argmax(output[0])\n",
        "        prediction_labels.append(predicted_label)\n",
        "\n",
        "    prediction_labels = np.array(prediction_labels)\n",
        "    accuracy = np.sum(prediction_labels == test_labels) / len(test_labels)\n",
        "    return accuracy\n",
        "\n",
        "accuracy = evaluate_tflite_model(interpreter, X_test_scaled, y_test)\n",
        "print(f\"Quantized Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPOZq-WeqS-p",
        "outputId": "73881ea5-0212-4538-9400-f8a6af7bfee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized Model Accuracy: 67.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Orijinal modelin boyutunun alınması\n",
        "original_model_size = os.path.getsize('original_model.h5') / (1024 ** 2)  # MB cinsinden\n",
        "\n",
        "# Pruned modelin boyutunun alınması\n",
        "pruned_model_size = os.path.getsize('pruned_model.h5') / (1024 ** 2)  # MB cinsinden\n",
        "\n",
        "# Kuantize edilmiş modelin boyutunu hesaplama\n",
        "quantized_model_size = os.path.getsize('quantized_model.tflite') / (1024 ** 2)\n",
        "\n",
        "\n",
        "print(f\"Original Model Size: {original_model_size:.2f} MB\")\n",
        "print(f\"Pruned Model Size: {pruned_model_size:.2f} MB\")\n",
        "print(f\"Quantized Model Size: {quantized_model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbOQ9fwElGlP",
        "outputId": "78134ea3-dc02-4ad3-a0ee-57ae2b3ff32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Size: 183.07 MB\n",
            "Pruned Model Size: 61.05 MB\n",
            "Quantized Model Size: 15.26 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MSn90yFPHtd"
      },
      "source": [
        "KAMERA BÖLÜMÜ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qInBPHKsolFw"
      },
      "outputs": [],
      "source": [
        "def predict_fruit(frame):\n",
        "    # Modelinize göre görüntüyü önişleme yapabilir ve tahminlerde bulunabilirsiniz.\n",
        "    # Örnek olarak, resmi yeniden boyutlandırma ve normalleştirme işlemleri yapalım.\n",
        "    resized_frame = cv2.resize(frame, (180, 180))\n",
        "    normalized_frame = resized_frame / 255.0  # Örnek normalizasyon\n",
        "\n",
        "    # Tahmin\n",
        "    predictions = model.predict(np.expand_dims(normalized_frame, axis=0))\n",
        "\n",
        "    # Sınıf indeksi\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "    # Sınıf etiketi\n",
        "    class_labels = {0: 'Apple', 1: 'Orange', 2: 'Mandarin'}\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    # Görüntü üzerine sonuçları çizme\n",
        "    cv2.putText(frame, f'Predicted Fruit: {predicted_class_label}', (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3KCoUtlkqsZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import base64\n",
        "\n",
        "# JavaScript ile video akışını açma işlemi\n",
        "def video_stream():\n",
        "    js = Javascript('''\n",
        "        var video;\n",
        "        var div = null;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "        var imgElement;\n",
        "        var labelElement;\n",
        "\n",
        "        var pendingResolve = null;\n",
        "        var shutdown = false;\n",
        "\n",
        "        function removeDom() {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "            video = null;\n",
        "            div = null;\n",
        "            stream = null;\n",
        "            imgElement = null;\n",
        "            captureCanvas = null;\n",
        "            labelElement = null;\n",
        "        }\n",
        "\n",
        "        function onAnimationFrame() {\n",
        "            if (!shutdown) {\n",
        "                window.requestAnimationFrame(onAnimationFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "                var result = \"\";\n",
        "                if (!shutdown) {\n",
        "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                    result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "                }\n",
        "                var lp = pendingResolve;\n",
        "                pendingResolve = null;\n",
        "                lp(result);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function createDom() {\n",
        "            if (div !== null) {\n",
        "                return stream;\n",
        "            }\n",
        "\n",
        "            div = document.createElement('div');\n",
        "            div.style.border = '2px solid black';\n",
        "            div.style.padding = '3px';\n",
        "            div.style.width = '100%';\n",
        "            div.style.maxWidth = '600px';\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const modelOut = document.createElement('div');\n",
        "            modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "            labelElement = document.createElement('span');\n",
        "            labelElement.innerText = 'No data';\n",
        "            labelElement.style.fontWeight = 'bold';\n",
        "            modelOut.appendChild(labelElement);\n",
        "            div.appendChild(modelOut);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.width = div.clientWidth - 6;\n",
        "            video.setAttribute('playsinline', '');\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: \"environment\" } });\n",
        "            div.appendChild(video);\n",
        "\n",
        "            imgElement = document.createElement('img');\n",
        "            imgElement.style.position = 'absolute';\n",
        "            imgElement.style.zIndex = 1;\n",
        "            imgElement.onclick = () => { shutdown = true; };\n",
        "            div.appendChild(imgElement);\n",
        "\n",
        "            const instruction = document.createElement('div');\n",
        "            instruction.innerHTML = '<span style=\"color: red; font-weight: bold;\">' +\n",
        "                'When finished, click here or on the video to stop this demo</span>';\n",
        "            div.appendChild(instruction);\n",
        "            instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640;\n",
        "            captureCanvas.height = 480;\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        async function stream_frame(label, imgData) {\n",
        "            if (shutdown) {\n",
        "                removeDom();\n",
        "                shutdown = false;\n",
        "                return '';\n",
        "            }\n",
        "\n",
        "            var preCreate = Date.now();\n",
        "            stream = await createDom();\n",
        "\n",
        "            var preShow = Date.now();\n",
        "            if (label !== \"\") {\n",
        "                labelElement.innerHTML = label;\n",
        "            }\n",
        "\n",
        "            if (imgData !== \"\") {\n",
        "                var videoRect = video.getClientRects()[0];\n",
        "                imgElement.style.top = videoRect.top + \"px\";\n",
        "                imgElement.style.left = videoRect.left + \"px\";\n",
        "                imgElement.style.width = videoRect.width + \"px\";\n",
        "                imgElement.style.height = videoRect.height + \"px\";\n",
        "                imgElement.src = imgData;\n",
        "            }\n",
        "\n",
        "            var preCapture = Date.now();\n",
        "            var result = await new Promise(function (resolve, reject) {\n",
        "                pendingResolve = resolve;\n",
        "            });\n",
        "            shutdown = false;\n",
        "\n",
        "            return {\n",
        "                'create': preShow - preCreate,\n",
        "                'show': preCapture - preShow,\n",
        "                'capture': Date.now() - preCapture,\n",
        "                'img': result\n",
        "            };\n",
        "        }\n",
        "        ''')\n",
        "\n",
        "    display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "    data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "    return data\n",
        "\n",
        "# video_stream fonksiyonunu çağırarak video akışını başlatın\n",
        "video_stream()\n",
        "\n",
        "# etiket için video\n",
        "label_html = 'Capturing...'\n",
        "# başlangıçta bounding box'ı boş olarak başlat\n",
        "bbox = ''\n",
        "count = 0\n",
        "\n",
        "# Tanınan meyveleri tanımla\n",
        "class_labels = {0: 'Apple', 1: 'Orange', 2: 'Mandarin', 3: 'Banana'}\n",
        "\n",
        "# Kamera görüntüsünü al ve göster\n",
        "while True:\n",
        "    # Her döngünün başında toplam meyve sayısını sıfırla\n",
        "    total_fruit_count = 0\n",
        "\n",
        "\n",
        "    # Başlangıç zamanını kaydet\n",
        "    start_time = time.time()\n",
        "\n",
        "    # JavaScript tarafından dönen veriyi işleme\n",
        "    js_result = video_frame(label_html, bbox)['img']\n",
        "\n",
        "    # Base64 kodlu görüntü verisini çözümleme\n",
        "    image_data = base64.b64decode(js_result.split(',')[1])\n",
        "\n",
        "    # Görüntüyü OpenCV ile açma\n",
        "    frame = cv2.imdecode(np.frombuffer(image_data, np.uint8), -1)\n",
        "\n",
        "    # Modelinizi kullanarak meyve tanıma işlemi\n",
        "    # Bu kısmı modelinize ve veri ön işleme işlemlerinize göre özelleştirebilirsiniz\n",
        "    resized_frame = cv2.resize(frame, (180, 180))\n",
        "    normalized_frame = resized_frame / 255.0\n",
        "    predictions = model.predict(np.expand_dims(normalized_frame, axis=0))\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "    # Tanınan meyveyi etiketle, tanımlı meyveler dışındakiler için \"Tanımsız\" etiketi ver\n",
        "    predicted_class_label = class_labels.get(predicted_class_index, 'Tanımsız')\n",
        "\n",
        "    # Görüntü üzerine sonuçları çizme\n",
        "    cv2.putText(frame, f'Predicted Fruit: {predicted_class_label}', (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Görüntüyü göster\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Bitiş zamanını kaydet\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Detection speed'i hesapla ve yazdır\n",
        "    detection_speed = 1 / (end_time - start_time)\n",
        "    print(f\"Detection Speed: {detection_speed:.2f} frames per second\")\n",
        "\n",
        "      # 1 saniye beklet\n",
        "    time.sleep(6)\n",
        "\n",
        "    # Çıkış için 'q' tuşuna basılmasını bekleyin\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1bM3pqH9synLBiokSufW50cgPFVmCnpwk",
      "authorship_tag": "ABX9TyMcYvmvf4Xu+t126bDW0AkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}